## 📚 Part 1: Introduction to Graph Learning
## 1장. 그래프 학습 시작하기 (Getting Started with Graph Learning)

> **왜 그래프인가?** - 데이터 표현으로서의 그래프의 중요성
> **왜 그래프 학습인가?** - 그래프 학습의 중요성과 다양한 응용 분야
> **왜 그래프 신경망인가?** - GNN의 특징과 다른 방법들과의 차이점

---

### 🎯 1. 왜 그래프인가? (Why graphs?)
#### 그래프란?
> 그래프는 **노드(node)** 라고 불리는 점들과, 노드들을 연결하는 **에지(edge)** 라고 불리는 선분들로 이루어진 데이터 구조입니다. 쉽게 말해, 점과 선으로 이루어진 그림이라고 생각하면 됩니다.

**그래프의 핵심 특징**
- 노드(정점)와 에지(간선)로 구성된 데이터 구조
- 고정된 구조가 없어 유연한 데이터 표현 가능
- 복잡한 시스템과 관계를 이해하는 수학적 도구

**그래프 이론의 중요성**
그래프 이론은 복잡한 시스템과 관계를 이해하기 위한 근본적인 도구로 등장했습니다. 복잡한 시스템을 상호작용하는 개체들의 네트워크로 표현함으로써, 우리는 그들의 관계를 분석하고 기본 구조와 패턴에 대한 더 깊은 이해를 얻을 수 있습니다.

**적용 분야**
| 분야 | 활용 예시 |
|------|-----------|
| 컴퓨터 과학 | 웹 페이지 링크 분석, 소셜 네트워크, 프로그램 구조 모델링 |
| 물리학 | 입자 상호작용, 네트워크 시스템 |
| 생물학 | 단백질 상호작용, 유전자 네트워크, 대사 경로 모델링 |
| 사회과학 | 인맥 관계, 커뮤니티 구조 |
| 금융 | 거래 관계, 위험 분석 |
| 공학 | 회로 설계, 교통 네트워크, 전력 그리드 모델링 |

**그래프의 유연성**
그래프는 관계형 구조가 자연스러운 분야뿐만 아니라, 관계형 구조가 덜 자연스러운 분야에도 적용할 수 있어 새로운 통찰과 이해를 제공합니다.

**다양한 데이터의 그래프 표현**
- **이미지**: 각 픽셀을 노드로, 인접 픽셀 간의 관계를 에지로 표현
- **문장**: 각 단어를 노드로, 인접 단어 간의 관계를 에지로 표현
- **분자 구조**: 원자를 노드로, 화학 결합을 에지로 표현

**그래프의 도전과제**
- 임의의 수의 노드와 에지를 가질 수 있음
- 특정 순서가 없음
- 동적 데이터 표현 가능 (시간에 따라 연결 관계가 변화)

---

### 🔍 2. 왜 그래프 학습인가? (Why graph learning?)

그래프 학습은 그래프 데이터에 머신러닝 기법을 적용하는 것입니다. 이 연구 영역은 그래프 구조 데이터를 이해하고 조작하는 것을 목표로 하는 다양한 작업을 포함합니다.

**주요 그래프 학습 작업**

| 작업 | 설명 | 예시 |
|------|------|------|
| 노드 분류 (Node Classification) | 그래프 내 노드의 카테고리를 예측하는 작업 | 온라인 사용자나 아이템을 특성에 따라 분류, Fab 장비 그룹의 Bottleneck 예측 |
| 링크 예측 (Link Prediction) | 그래프에서 노드 쌍 간의 누락된 링크를 예측하는 작업 | 소셜 네트워크에서 친구 추천, Fab에서 장비 그룹의 Critical path |
| 그래프 분류 (Graph Classification) | 서로 다른 그래프를 미리 정의된 카테고리로 분류하는 작업 | 분자 구조를 그래프로 표현하고 약물 설계를 위한 특성 예측 |
| 그래프 생성 (Graph Generation) | 원하는 속성을 기반으로 새로운 그래프를 생성하는 작업 | 신약 발견을 위한 새로운 분자 구조 생성 |

**실용적 응용 분야**
- **추천 시스템**: 사용자의 이전 상호작용과 다른 아이템들과의 관계를 기반으로 관련 아이템 추천
- **교통 예측**: 다양한 경로와 교통 수단 간의 복잡한 관계를 고려하여 여행 시간 예측 개선

**그래프 학습 기법의 네 가지 주요 패밀리**

| 기법 | 설명 |
|------|------|
| 그래프 신호 처리 (Graph Signal Processing) | 그래프 푸리에 변환, 스펙트럴 분석 등 전통적인 신호 처리 방법을 그래프에 적용 |
| 행렬 분해 (Matrix Factorization) | 큰 행렬의 저차원 표현을 찾는 것을 목표로 하며, 원본 행렬에서 관찰된 관계를 설명하는 잠재적 요인이나 패턴을 식별 |
| 랜덤 워크 (Random Walk) | 그래프에서 개체의 움직임을 모델링하는 수학적 개념으로, 그래프 위에서 랜덤 워크를 시뮬레이션하여 노드 간 관계에 대한 정보 수집 |
| 딥러닝 (Deep Learning) | 여러 층을 가진 신경망에 초점을 맞춘 머신러닝의 하위 분야로, 그래프 데이터를 벡터로 효과적으로 인코딩하고 표현 |

**데이터셋의 중요성**
전통적인 표 형태 데이터셋은 각 행이 단일 데이터 포인트를 나타내는 행과 열로 데이터를 표현합니다. 그러나 많은 실제 시나리오에서 데이터 포인트 간의 관계는 데이터 포인트 자체만큼 의미가 있습니다. 그래프 데이터셋은 데이터 포인트를 그래프의 노드로, 그들 간의 관계를 에지로 표현합니다.

---

### 🧠 3. 왜 그래프 신경망인가? (Why graph neural networks?)

이 책에서는 그래프 학습 기법의 딥러닝 패밀리에 초점을 맞출 것입니다. GNN은 그래프 구조 데이터를 위해 특별히 설계된 새로운 딥러닝 아키텍처 카테고리입니다.

**GNN의 특징**
- 텍스트와 이미지를 위해 주로 개발된 전통적인 딥러닝 알고리즘과 달리, 그래프 데이터셋을 처리하고 분석하도록 명시적으로 만들어짐
- 그래프 학습을 위한 강력한 도구로 등장하여 다양한 작업과 산업에서 우수한 결과를 보임

**GNN의 성공 사례**
가장 놀라운 예시 중 하나는 GNN 모델이 새로운 항생제를 식별한 것입니다:
- 2,500개의 분자로 훈련된 모델
- 6,000개 화합물 라이브러리에서 테스트
- halicin이라는 분자가 항생제 내성 박테리아를 죽일 수 있으면서 인간 세포에 대한 독성이 낮을 것이라고 예측
- 실제로 항생제 내성 박테리아에 감염된 쥐를 치료하는 데 효과를 입증

**GNN의 작동 원리**
노드 분류 작업을 예로 들어보겠습니다:

**정보 통합**
GNN은 그래프의 각 노드에 대한 벡터 표현을 만들기 위해 다양한 소스의 정보를 활용합니다:
- **원본 노드 특성**: 이름, 나이, 성별 등
- **에지 특성**: 노드 간 관계의 강도
- **전역 특성**: 네트워크 전체 통계

**전통적 기법과의 차이점**
GNN은 원본 속성에만 국한되지 않고, 인접 노드, 에지, 전역 특성의 속성으로 원본 노드 특성을 풍부하게 만들어 표현을 훨씬 더 포괄적이고 의미 있게 만듭니다.

**그래프 컨볼루션 연산**
GNN은 인접 노드와 에지의 정보를 집계하여 노드 표현을 업데이트하는 그래프 컨볼루션 연산을 정의합니다. 이 연산은 반복적으로 수행되어 반복 횟수가 증가함에 따라 노드 간의 더 복잡한 관계를 학습할 수 있습니다.

**GNN의 다양한 변형**
실제로는 다양한 종류의 GNN과 GNN 층이 있으며, 각각은 고유한 구조와 인접 노드로부터 정보를 집계하는 방식이 있습니다. 이러한 GNN의 다양한 변형들은 각각의 장단점이 있으며 특정 유형의 그래프 데이터와 작업에 적합합니다.

**GNN의 적용 조건**
- **높은 복잡성**: 좋은 표현을 학습하는 것이 작업 해결에 중요한 문제
- **대량의 데이터**: 효과적인 성능을 위해 상당한 양의 데이터 필요
- **확장성**: 병렬 및 분산 훈련 덕분에 더 큰 데이터셋 처리 가능
- **효율성**: 추가 정보를 더 효율적으로 활용하여 더 나은 결과 생성

**GNN의 한계**
- 작은 데이터셋의 경우 전통적인 머신러닝 기법이 더 적합할 수 있음
- 특정 문제에만 효과적 (모든 문제에 만능은 아님)

---

### 📊 그래프 vs 표 형태 데이터 비교

**표 형태 데이터의 한계**
```
이름    | 나이 | 성별
김철수  | 25   | 남
김영희  | 23   | 여
김민수  | 50   | 남
```

**그래프 데이터의 장점**
- 사람들 간의 관계(부모-자식, 형제 등)를 명확히 표현
- 관계 정보가 데이터 이해에 중요한 상황에서 유용
- 연결성과 패턴을 시각적으로 파악 가능
