### 5장. 기본 인공신경망을 사용한 노드 특성값 포함시키기

#### 🧮 MLP 구현 및 학습

**MLP 클래스 구성**
- `__init__`: 모델 초기화
- `forward`: 순전파
- `fit`: 모델 학습
- `test`: 테스트 정확도 반환

**학습 설정**
- **손실 함수**: `torch.nn.CrossEntropyLoss()`
- **옵티마이저**: `torch.optim.Adam()`
- **정확도**: 정답 예측 개수 / 총 예측 개수

#### 📈 성능 평가 결과

| 데이터셋 | 노드 수 | 특징 수 | 클래스 수 | MLP 정확도 |
|----------|---------|---------|-----------|------------|
| Cora | 2,708 | 1,433 | 7 | 52.50% |
| Facebook | 22,470 | 128 | 4 | 74.52% |

#### 🎯 Vanilla GNN 구현

**VanillaGNNLayer 특징**
- 입력 차원과 출력 차원을 받아 선형 변환 수행
- 인접 행렬과의 곱셈으로 이웃 노드 특징 고려
- Self-loop 추가: Ã = A + I

**VanillaGNN 구조**
- 두 개의 VanillaGNNLayer 사용
- MLP와 유사한 학습 구조
- CrossEntropyLoss + Adam 옵티마이저

#### 🏆 성능 비교

> **결과 요약**
> 
> Vanilla GNN이 두 데이터셋 모두에서 MLP보다 높은 정확도를 보입니다. 
> 이는 토폴로지 정보를 활용한 GNN의 우수성을 보여줍니다.

**GNN의 실용적 적용**
- **신약 개발**: 새로운 항생제 발견
- **추천 시스템**: 사용자-상품 관계 분석
- **교통 예측**: 다양한 경로와 교통 수단 관계 고려

---

## 🎯 GNN 작동 원리

### 🔄 핵심 메커니즘

**그래프 합성곱 연산**
- 이웃 노드와 에지 정보를 집계
- 노드 표현을 반복적으로 업데이트
- 복잡한 노드 간 관계 학습

**포괄적 특징 고려**
- 노드 특징
- 에지 특징  
- 전역 특징

### ⚖️ GNN의 장단점

| 장점 | 한계 |
|------|------|
| 복잡한 관계형 데이터 처리 효과적 | 많은 학습 데이터 필요 |
| 대규모 데이터셋 처리 가능 | 특정 문제에만 효과적 |
| 우수한 성능 | 복잡한 구조로 해석 어려움 |
